{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will use straightforward application of multilayered long short-term memory (LSTM) architecture with attention-mechanism to map the input sequence to a vector of a fixed dimensionality, and then another LSTM to decode the target sequence from the vector. Our main focus will be on an English to Roman Urdu translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import basic libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set basic parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 10\n",
    "EPOCH = 100\n",
    "LATENT_DIM = 500\n",
    "LATENT_DIM_DECODER = LATENT_DIM\n",
    "SAMPLES = 1000\n",
    "MAX_WORD_NUM = SAMPLES\n",
    "MAX_SEQ_LEN = 100\n",
    "EMBEDDING = MAX_SEQ_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store data from textfile to usable arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Count: 100.\n",
      "Sample Count: 200.\n",
      "Sample Count: 300.\n",
      "Sample Count: 400.\n",
      "Sample Count: 500.\n",
      "Sample Count: 600.\n",
      "Sample Count: 700.\n",
      "Sample Count: 800.\n",
      "Sample Count: 900.\n"
     ]
    }
   ],
   "source": [
    "eng = []\n",
    "man = []\n",
    "man_inputs = []\n",
    "count = 0\n",
    "\n",
    "# preprocess the translation file\n",
    "for line in open('romanu.txt', 'r', encoding='utf-8'):\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    \n",
    "    count += 1\n",
    "    if (count > SAMPLES):\n",
    "        break\n",
    "    \n",
    "    # split original and translation into lists\n",
    "    e, m, _ = line.rstrip().split('\\t')\n",
    "    eng.append(e)\n",
    "    man.append(m + ' <eos>')\n",
    "    man_inputs.append('<sos> ' + m)\n",
    "    \n",
    "    if (count % 100 == 0):\n",
    "        print ('Sample Count: {}.'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Count: 100.\n",
      "Sample Count: 200.\n",
      "Sample Count: 300.\n"
     ]
    }
   ],
   "source": [
    "engT = []\n",
    "manT = []\n",
    "man_inputsT = []\n",
    "count = 0\n",
    "\n",
    "# preprocess the translation file\n",
    "for line in open('roman_train.txt', 'r', encoding='utf-8'):\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    \n",
    "    count += 1\n",
    "    if (count > SAMPLES):\n",
    "        break\n",
    "    \n",
    "    # split original and translation into lists\n",
    "    eT, mT, _ = line.rstrip().split('\\t')\n",
    "    engT.append(eT)\n",
    "    manT.append(mT + ' <eos>')\n",
    "    man_inputsT.append('<sos> ' + mT)\n",
    "    \n",
    "    if (count % 100 == 0):\n",
    "        print ('Sample Count: {}.'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the input and output sentences, and create maps that can be used by the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input tokens: 1185\n",
      "Maximum input sequence length: 17\n",
      "Number of output tokens: 1485\n",
      "Maximum output sequence length: 20\n"
     ]
    }
   ],
   "source": [
    "#train data tokenization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# tokenize input and generate idx map\n",
    "tok_in = Tokenizer(num_words=MAX_WORD_NUM)\n",
    "tok_in.fit_on_texts(eng)\n",
    "eng_seq = tok_in.texts_to_sequences(eng)\n",
    "word2idx_in = tok_in.word_index\n",
    "max_in_len = max(len(s) for s in eng_seq)\n",
    "\n",
    "print(\"Number of input tokens: {}\".format(len(word2idx_in)))\n",
    "print(\"Maximum input sequence length: {}\".format(max_in_len))\n",
    "\n",
    "# tokenize output and generate idx map\n",
    "tok_out = Tokenizer(num_words=MAX_WORD_NUM, filters='')\n",
    "tok_out.fit_on_texts(man + man_inputs)\n",
    "man_seq = tok_out.texts_to_sequences(man)\n",
    "man_seq_inputs = tok_out.texts_to_sequences(man_inputs)\n",
    "word2idx_out = tok_out.word_index\n",
    "max_out_len = max(len(s) for s in man_seq)\n",
    "out_word_num = len(word2idx_out) + 1\n",
    "\n",
    "print(\"Number of output tokens: {}\".format(len(word2idx_out)))\n",
    "print(\"Maximum output sequence length: {}\".format(max_out_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input tokens: 538\n",
      "Maximum input sequence length: 8\n",
      "Number of output tokens: 671\n",
      "Maximum output sequence length: 15\n"
     ]
    }
   ],
   "source": [
    "#test data tokenization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# tokenize input and generate idx map\n",
    "tok_inT = Tokenizer(num_words=MAX_WORD_NUM)\n",
    "tok_inT.fit_on_texts(engT)\n",
    "eng_seqT = tok_inT.texts_to_sequences(engT)\n",
    "word2idx_inT = tok_inT.word_index\n",
    "max_in_lenT = max(len(s) for s in eng_seqT)\n",
    "\n",
    "print(\"Number of input tokens: {}\".format(len(word2idx_inT)))\n",
    "print(\"Maximum input sequence length: {}\".format(max_in_lenT))\n",
    "\n",
    "# tokenize output and generate idx map\n",
    "tok_outT = Tokenizer(num_words=MAX_WORD_NUM, filters='')\n",
    "tok_outT.fit_on_texts(manT + man_inputsT)\n",
    "man_seqT = tok_out.texts_to_sequences(manT)\n",
    "man_seq_inputsT = tok_outT.texts_to_sequences(man_inputsT)\n",
    "word2idx_outT = tok_outT.word_index\n",
    "max_out_lenT = max(len(s) for s in man_seqT)\n",
    "out_word_numT = len(word2idx_outT) + 1\n",
    "\n",
    "print(\"Number of output tokens: {}\".format(len(word2idx_outT)))\n",
    "print(\"Maximum output sequence length: {}\".format(max_out_lenT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad the input and output sequences to be the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "eng_seq_padded = pad_sequences(eng_seq, maxlen=max_in_len)\n",
    "man_seq_padded = pad_sequences(man_seq, maxlen=max_out_len, padding='post')\n",
    "man_seq_inputs_padded = pad_sequences(man_seq_inputs, maxlen=max_out_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding for test dataset\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "eng_seq_paddedT = pad_sequences(eng_seqT, maxlen=max_in_len)\n",
    "man_seq_paddedT = pad_sequences(man_seqT, maxlen=max_out_len, padding='post')\n",
    "man_seq_inputs_paddedT = pad_sequences(man_seq_inputsT, maxlen=max_out_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in fasttext word vectors and use them to create word embeddings. [The dataset](https://fasttext.cc/docs/en/crawl-vectors.html) of the word vectors is downloaded from *fasttext.cc*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wordVec\n",
      "Finished loading wordVec.\n"
     ]
    }
   ],
   "source": [
    "wordVec = {}\n",
    "\n",
    "print('Loading wordVec')\n",
    "import io\n",
    "\n",
    "fin = io.open('cc.en.300.bin', 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "n, d = map(lambda x: (str, int)[x.isdigit() or x.strip(\"-\").isdigit()](x), fin.readline().split())\n",
    "data = {}\n",
    "for line in fin:\n",
    "    tokens = line.rstrip().split(' ')\n",
    "    data[tokens[0]] = map(float, tokens[1:])\n",
    "print('Finished loading wordVec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordNum = min(MAX_WORD_NUM, len(word2idx_in) + 1)\n",
    "word_embedding = np.zeros((wordNum, EMBEDDING))\n",
    "\n",
    "# create word embedding by fetching each word vector\n",
    "for tok, idx in word2idx_in.items():\n",
    "    if idx < MAX_WORD_NUM:\n",
    "        word_vector = wordVec.get(tok)\n",
    "        if word_vector is not None:\n",
    "            word_embedding[idx] = word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create translated target matrix by loading the padded output target sequence using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_target_one_hot = np.zeros((len(eng), max_out_len, out_word_num), dtype='float32')\n",
    "\n",
    "for idx, tokVec in enumerate(man_seq_padded):\n",
    "    for tok_idx, tok in enumerate(tokVec):\n",
    "        if (tok > 0):\n",
    "            man_target_one_hot[idx, tok_idx, tok] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the encoder and decoder before attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, LSTM, GRU, Dense, Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "# Embedding\n",
    "embedding = Embedding(wordNum, EMBEDDING, weights=[word_embedding], input_length=max_in_len)\n",
    "\n",
    "# Encoder\n",
    "input_layer_encoder = Input(shape=(max_in_len,))\n",
    "embed_encoder = embedding(input_layer_encoder)\n",
    "encoder = Bidirectional(LSTM(LATENT_DIM, return_sequences=True, dropout=0.2))\n",
    "encoder_out = encoder(embed_encoder)\n",
    "\n",
    "# Decoder input\n",
    "input_layer_decoder = Input(shape=(max_out_len,))\n",
    "embed_decoder = Embedding(out_word_num, EMBEDDING)\n",
    "decoder_input = embed_decoder(input_layer_decoder)\n",
    "\n",
    "# Decoder output, after attention\n",
    "decoder = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "dense_decode = Dense(out_word_num, activation='softmax')\n",
    "s0 = Input(shape=(LATENT_DIM_DECODER,))\n",
    "c0 = Input(shape=(LATENT_DIM_DECODER,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Attention. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of x is N x T x D.\n",
    "def softmax(x):\n",
    "    assert(K.ndim(x) > 2)\n",
    "    e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "    s = K.sum(e, axis=1, keepdims=True)\n",
    "    return e / s\n",
    "\n",
    "# Some of the common layers for attention\n",
    "repeat_attn = RepeatVector(max_in_len)\n",
    "concat_attn = Concatenate(axis=-1)\n",
    "dense1_attn = Dense(10, activation='tanh')  # over time dimension T\n",
    "dense2_attn = Dense(1, activation=softmax)\n",
    "dot_attn = Dot(axes=1)                      # over time dimension T\n",
    "\n",
    "def iterAttn(h, prevOut):\n",
    "    \"\"\"\n",
    "    h: encoder encoded hidden states at all time.\n",
    "    prevOut: output at the previous time (word).\n",
    "    An iteration of attention.\n",
    "    \"\"\"\n",
    "    prevOutRepeat = repeat_attn(prevOut) # Tx, LATENT_DIM_DECODE\n",
    "    total = concat_attn([h, prevOutRepeat]) # Tx, LATENT_DIM_DECODE + LATENT_DIM * 2\n",
    "    d = dense1_attn(total)\n",
    "    alphaLayer = dense2_attn(d)\n",
    "    context = dot_attn([alphaLayer, h])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute encoder-decoder and attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s0\n",
    "c = c0\n",
    "\n",
    "# Iterate attention Ty times\n",
    "all_out = []\n",
    "for t in range(max_out_len):\n",
    "    # Get context vector with encoder and attention\n",
    "    context = iterAttn(encoder_out, s) \n",
    "    \n",
    "    # For teacher forcing, get the previous word\n",
    "    select_layer = Lambda(lambda x: x[:, t:t+1])\n",
    "    prevWord = select_layer(decoder_input)\n",
    "    \n",
    "    # Concat context and previous word as decoder input\n",
    "    concat2 = Concatenate(axis=2)\n",
    "    decoder_in_concat = concat2([context, prevWord])\n",
    "    \n",
    "    # pass into decoder, inference output\n",
    "    pred, s, c = decoder(decoder_in_concat, initial_state=[s, c])\n",
    "    pred = dense_decode(pred)\n",
    "    all_out.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output needs to be stacked to be considered as the network's output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(outputs):\n",
    "    outputs = K.stack(outputs)\n",
    "    return K.permute_dimensions(outputs, pattern=(1, 0, 2))\n",
    "\n",
    "stack_layer = Lambda(stack)\n",
    "all_out = stack_layer(all_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "attnModel = Model(inputs=[input_layer_encoder, input_layer_decoder, s0, c0,],\n",
    "                 outputs=all_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define customized loss and accuracy metrics for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myLoss(y_train, pred):\n",
    "    mask = K.cast(y_train > 0, dtype='float32')\n",
    "    val = mask * y_train * K.log(pred)\n",
    "    return -K.sum(val) / K.sum(mask)\n",
    "\n",
    "def acc(y_train, pred):\n",
    "    targ = K.argmax(y_train, axis=-1)\n",
    "    pred = K.argmax(pred, axis=-1)\n",
    "    correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
    "\n",
    "    mask = K.cast(K.greater(targ, 0), dtype='float32') # filter out padding value 0.\n",
    "    correctCount = K.sum(mask * correct)\n",
    "    totalCount = K.sum(mask)\n",
    "    return correctCount / totalCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model using Adam optimizer and defined loss and metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 159s 849ms/step - loss: 6.2564 - acc: 0.1313 - val_loss: 5.9129 - val_acc: 0.1138\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 34s 478ms/step - loss: 5.0757 - acc: 0.1781 - val_loss: 5.7847 - val_acc: 0.1182\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 34s 475ms/step - loss: 4.8553 - acc: 0.1812 - val_loss: 5.8966 - val_acc: 0.1191\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 34s 484ms/step - loss: 4.6954 - acc: 0.1920 - val_loss: 6.0741 - val_acc: 0.1266\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 35s 488ms/step - loss: 4.5076 - acc: 0.1995 - val_loss: 6.3314 - val_acc: 0.1290\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 37s 521ms/step - loss: 4.4444 - acc: 0.1946 - val_loss: 6.4653 - val_acc: 0.1254\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 35s 492ms/step - loss: 4.3221 - acc: 0.2019 - val_loss: 6.6450 - val_acc: 0.1285\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 33s 468ms/step - loss: 4.2649 - acc: 0.1999 - val_loss: 6.8157 - val_acc: 0.1271\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 34s 486ms/step - loss: 4.1870 - acc: 0.2017 - val_loss: 6.8038 - val_acc: 0.1294\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 36s 508ms/step - loss: 4.0650 - acc: 0.2171 - val_loss: 6.8509 - val_acc: 0.1274\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 37s 521ms/step - loss: 4.0391 - acc: 0.2046 - val_loss: 7.1037 - val_acc: 0.1267\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 34s 483ms/step - loss: 3.9942 - acc: 0.2106 - val_loss: 7.1657 - val_acc: 0.1278\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 37s 520ms/step - loss: 3.9300 - acc: 0.2080 - val_loss: 7.0459 - val_acc: 0.1267\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 34s 475ms/step - loss: 3.9036 - acc: 0.2135 - val_loss: 7.1500 - val_acc: 0.1246\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 36s 503ms/step - loss: 3.8275 - acc: 0.2122 - val_loss: 7.7079 - val_acc: 0.1251\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 35s 489ms/step - loss: 3.8473 - acc: 0.2120 - val_loss: 7.3424 - val_acc: 0.1225\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 36s 513ms/step - loss: 3.8364 - acc: 0.2093 - val_loss: 7.5752 - val_acc: 0.1219\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 36s 506ms/step - loss: 3.7406 - acc: 0.2161 - val_loss: 7.6686 - val_acc: 0.1219\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 37s 521ms/step - loss: 3.6703 - acc: 0.2161 - val_loss: 7.6950 - val_acc: 0.1227\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 35s 496ms/step - loss: 3.6610 - acc: 0.2153 - val_loss: 7.7257 - val_acc: 0.1269\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 37s 521ms/step - loss: 3.6523 - acc: 0.2175 - val_loss: 7.6508 - val_acc: 0.1218\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 33s 465ms/step - loss: 3.5669 - acc: 0.2278 - val_loss: 7.8975 - val_acc: 0.1253\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 36s 504ms/step - loss: 3.5976 - acc: 0.2293 - val_loss: 7.8348 - val_acc: 0.1221\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 36s 505ms/step - loss: 3.5971 - acc: 0.2169 - val_loss: 7.9131 - val_acc: 0.1216\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 34s 478ms/step - loss: 3.4729 - acc: 0.2314 - val_loss: 8.0842 - val_acc: 0.1204\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 33s 468ms/step - loss: 3.4382 - acc: 0.2282 - val_loss: 8.1079 - val_acc: 0.1202\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 36s 501ms/step - loss: 3.4692 - acc: 0.2306 - val_loss: 8.2694 - val_acc: 0.1279\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 37s 520ms/step - loss: 3.4253 - acc: 0.2345 - val_loss: 8.1963 - val_acc: 0.1165\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 35s 501ms/step - loss: 3.4003 - acc: 0.2289 - val_loss: 8.2386 - val_acc: 0.1163\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 38s 535ms/step - loss: 3.3201 - acc: 0.2390 - val_loss: 8.1159 - val_acc: 0.1206\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 35s 492ms/step - loss: 3.3101 - acc: 0.2333 - val_loss: 8.2606 - val_acc: 0.1181\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 36s 503ms/step - loss: 3.2065 - acc: 0.2510 - val_loss: 8.3460 - val_acc: 0.1189\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 38s 532ms/step - loss: 3.2662 - acc: 0.2468 - val_loss: 8.3791 - val_acc: 0.1227\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 38s 537ms/step - loss: 3.1987 - acc: 0.2511 - val_loss: 8.6063 - val_acc: 0.1170\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 36s 506ms/step - loss: 3.0986 - acc: 0.2637 - val_loss: 8.5458 - val_acc: 0.1172\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 37s 525ms/step - loss: 3.0375 - acc: 0.2750 - val_loss: 8.5503 - val_acc: 0.1157\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 38s 531ms/step - loss: 3.0017 - acc: 0.2778 - val_loss: 8.7558 - val_acc: 0.1118\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 36s 514ms/step - loss: 2.9463 - acc: 0.2804 - val_loss: 8.7332 - val_acc: 0.1170\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 35s 493ms/step - loss: 2.8943 - acc: 0.2861 - val_loss: 8.6791 - val_acc: 0.1133\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 33s 470ms/step - loss: 2.8978 - acc: 0.2864 - val_loss: 8.8425 - val_acc: 0.1076\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 34s 476ms/step - loss: 2.8057 - acc: 0.3071 - val_loss: 8.9388 - val_acc: 0.1066\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 37s 520ms/step - loss: 2.7261 - acc: 0.3043 - val_loss: 8.9342 - val_acc: 0.1102\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 36s 511ms/step - loss: 2.7708 - acc: 0.3042 - val_loss: 9.1294 - val_acc: 0.1087\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 37s 527ms/step - loss: 2.6099 - acc: 0.3218 - val_loss: 9.1523 - val_acc: 0.1045\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 35s 491ms/step - loss: 2.5252 - acc: 0.3518 - val_loss: 9.2065 - val_acc: 0.1071\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 38s 530ms/step - loss: 2.5133 - acc: 0.3501 - val_loss: 9.3242 - val_acc: 0.1093\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 34s 473ms/step - loss: 2.4367 - acc: 0.3529 - val_loss: 9.3115 - val_acc: 0.1060\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 33s 472ms/step - loss: 2.3288 - acc: 0.3900 - val_loss: 9.4329 - val_acc: 0.1086\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 34s 481ms/step - loss: 2.3001 - acc: 0.3799 - val_loss: 9.5052 - val_acc: 0.1093\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 33s 460ms/step - loss: 2.1670 - acc: 0.4211 - val_loss: 9.5666 - val_acc: 0.1069\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 33s 459ms/step - loss: 2.1283 - acc: 0.4231 - val_loss: 9.6880 - val_acc: 0.1067\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 31s 442ms/step - loss: 2.0615 - acc: 0.4454 - val_loss: 9.6847 - val_acc: 0.1133\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 32s 453ms/step - loss: 2.0270 - acc: 0.4512 - val_loss: 9.7391 - val_acc: 0.1121\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 31s 438ms/step - loss: 2.0134 - acc: 0.4464 - val_loss: 9.7617 - val_acc: 0.1060\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 32s 447ms/step - loss: 1.8606 - acc: 0.4830 - val_loss: 9.7439 - val_acc: 0.1047\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 32s 455ms/step - loss: 1.7628 - acc: 0.5113 - val_loss: 9.9674 - val_acc: 0.1067\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 30s 428ms/step - loss: 2.1826 - acc: 0.4363 - val_loss: 9.8929 - val_acc: 0.1107\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 24s 337ms/step - loss: 1.7173 - acc: 0.5139 - val_loss: 9.9101 - val_acc: 0.1071\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 24s 340ms/step - loss: 1.6590 - acc: 0.5373 - val_loss: 10.1642 - val_acc: 0.1091\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 24s 335ms/step - loss: 1.5236 - acc: 0.5708 - val_loss: 10.3149 - val_acc: 0.1051\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 25s 354ms/step - loss: 1.3867 - acc: 0.6186 - val_loss: 10.2735 - val_acc: 0.1080\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 26s 361ms/step - loss: 1.4056 - acc: 0.6124 - val_loss: 10.3288 - val_acc: 0.1068\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 27s 383ms/step - loss: 1.3512 - acc: 0.6188 - val_loss: 10.2827 - val_acc: 0.1035\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 27s 384ms/step - loss: 1.2763 - acc: 0.6439 - val_loss: 10.6888 - val_acc: 0.1082\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 27s 377ms/step - loss: 1.2202 - acc: 0.6625 - val_loss: 10.6407 - val_acc: 0.1025\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 27s 382ms/step - loss: 1.2030 - acc: 0.6644 - val_loss: 10.8578 - val_acc: 0.1095\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 28s 390ms/step - loss: 1.1249 - acc: 0.6870 - val_loss: 10.6964 - val_acc: 0.1074\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 28s 394ms/step - loss: 1.0535 - acc: 0.7027 - val_loss: 10.7803 - val_acc: 0.1039\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 28s 394ms/step - loss: 1.0382 - acc: 0.7174 - val_loss: 10.8673 - val_acc: 0.1051\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 27s 381ms/step - loss: 0.9573 - acc: 0.7284 - val_loss: 11.1620 - val_acc: 0.1051\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 28s 393ms/step - loss: 1.0655 - acc: 0.7319 - val_loss: 10.7972 - val_acc: 0.1025\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 29s 411ms/step - loss: 1.0015 - acc: 0.7124 - val_loss: 11.1478 - val_acc: 0.1067\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 28s 396ms/step - loss: 0.8349 - acc: 0.7788 - val_loss: 11.2529 - val_acc: 0.1072\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 29s 412ms/step - loss: 0.7839 - acc: 0.7786 - val_loss: 11.2883 - val_acc: 0.0993\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 29s 413ms/step - loss: 0.7587 - acc: 0.7727 - val_loss: 11.4377 - val_acc: 0.1051\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 31s 432ms/step - loss: 0.7369 - acc: 0.7868 - val_loss: 11.5406 - val_acc: 0.1031\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 29s 407ms/step - loss: 0.6297 - acc: 0.8197 - val_loss: 11.5615 - val_acc: 0.1035\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 29s 404ms/step - loss: 0.6031 - acc: 0.8249 - val_loss: 11.7356 - val_acc: 0.1043\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 28s 396ms/step - loss: 0.5865 - acc: 0.8243 - val_loss: 11.7946 - val_acc: 0.1012\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 33s 473ms/step - loss: 0.5509 - acc: 0.8381 - val_loss: 11.7879 - val_acc: 0.0990\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 30s 419ms/step - loss: 0.5145 - acc: 0.8470 - val_loss: 11.8325 - val_acc: 0.1036\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 29s 413ms/step - loss: 0.5048 - acc: 0.8563 - val_loss: 11.9659 - val_acc: 0.1012\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 31s 444ms/step - loss: 0.4794 - acc: 0.8418 - val_loss: 11.9434 - val_acc: 0.1036\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 29s 406ms/step - loss: 0.4852 - acc: 0.8555 - val_loss: 11.9094 - val_acc: 0.1021\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 30s 416ms/step - loss: 0.4790 - acc: 0.8510 - val_loss: 11.9276 - val_acc: 0.1017\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 31s 436ms/step - loss: 0.4704 - acc: 0.8475 - val_loss: 12.2363 - val_acc: 0.0989\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 30s 424ms/step - loss: 0.5038 - acc: 0.8371 - val_loss: 11.9831 - val_acc: 0.1044\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 30s 420ms/step - loss: 0.5005 - acc: 0.8464 - val_loss: 12.2289 - val_acc: 0.0999\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 33s 472ms/step - loss: 0.4287 - acc: 0.8592 - val_loss: 12.2507 - val_acc: 0.0994\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 30s 421ms/step - loss: 0.3665 - acc: 0.8836 - val_loss: 12.3403 - val_acc: 0.1026\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 28s 397ms/step - loss: 0.3693 - acc: 0.8715 - val_loss: 12.3662 - val_acc: 0.0984\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 27s 387ms/step - loss: 0.3485 - acc: 0.8766 - val_loss: 12.6591 - val_acc: 0.0993\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 28s 399ms/step - loss: 0.3274 - acc: 0.8837 - val_loss: 12.6545 - val_acc: 0.0991\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 29s 405ms/step - loss: 0.3808 - acc: 0.8817 - val_loss: 12.6461 - val_acc: 0.0975\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 28s 401ms/step - loss: 0.4598 - acc: 0.8454 - val_loss: 12.4480 - val_acc: 0.1010\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 28s 388ms/step - loss: 0.4153 - acc: 0.8507 - val_loss: 12.7204 - val_acc: 0.1005\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 28s 395ms/step - loss: 0.3196 - acc: 0.8715 - val_loss: 12.8212 - val_acc: 0.1030\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 29s 407ms/step - loss: 0.3090 - acc: 0.8828 - val_loss: 12.6485 - val_acc: 0.1032\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 29s 414ms/step - loss: 0.3081 - acc: 0.8820 - val_loss: 12.7782 - val_acc: 0.1008\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 28s 400ms/step - loss: 0.2933 - acc: 0.8913 - val_loss: 12.6900 - val_acc: 0.1038\n"
     ]
    }
   ],
   "source": [
    "attnModel.compile(optimizer='Adam', loss=myLoss, metrics=[acc])\n",
    "\n",
    "# Define empty s0 and c0\n",
    "init_s = np.zeros((len(eng_seq_padded), LATENT_DIM_DECODER))\n",
    "init_c = np.zeros((len(eng_seq_padded), LATENT_DIM_DECODER))\n",
    "\n",
    "print(BATCHSIZE)\n",
    "\n",
    "# Train\n",
    "history = attnModel.fit(\n",
    "    x=[eng_seq_padded, man_seq_padded, init_s, init_c],\n",
    "    y=man_target_one_hot,\n",
    "    batch_size=BATCHSIZE,\n",
    "    epochs=EPOCH,\n",
    "    validation_split=0.22\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['acc'], label='acc')\n",
    "plt.plot(history.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "attnModel.save('attention_model_35_man.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in the inference model teacher forcing is not available, thus the model needs to be modified to use the previous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inf = Model(input_layer_encoder, encoder_out)\n",
    "encoder_out_inf = Input(shape=(max_in_len, LATENT_DIM * 2,))\n",
    "\n",
    "# Decoder\n",
    "decoder_in_inf = Input(shape=(1,))\n",
    "decoder_in_embed_inf = embed_decoder(decoder_in_inf)\n",
    "\n",
    "# Context, concat without teacher forcing.\n",
    "context_inf = iterAttn(encoder_out_inf, s0)\n",
    "decoder_in_concat_inf = concat2([context_inf, decoder_in_embed_inf])\n",
    "\n",
    "# Decoder inference\n",
    "pred, s, c = decoder(decoder_in_concat_inf, initial_state=[s0, c0])\n",
    "pred_out = dense_decode(pred)\n",
    "\n",
    "# Define model\n",
    "decoder_inf = Model(\n",
    "    inputs=[decoder_in_inf, encoder_out_inf, s0, c0],\n",
    "    outputs=[pred_out, s, c]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse the word-to-index maps to convert translated indices to words. Then use the inference encoder and decoder models to create predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_in = {b:a for a, b in word2idx_inT.items()}\n",
    "idx2word_out = {b:a for a, b in word2idx_outT.items()}\n",
    "\n",
    "def inference(eng_seq):\n",
    "    # Encode\n",
    "    encoder_output = encoder_inf.predict(eng_seq)\n",
    "    \n",
    "    # Create output seq matrix\n",
    "    target_output = np.zeros((1, 1))\n",
    "    target_output[0, 0] = word2idx_outT['<sos>']\n",
    "    \n",
    "    # init\n",
    "    eos = word2idx_outT['<eos>']\n",
    "    s0 = np.zeros((1, LATENT_DIM_DECODER))\n",
    "    c0 = np.zeros((1, LATENT_DIM_DECODER))\n",
    "    \n",
    "    output_seq = []\n",
    "    s = s0\n",
    "    c = c0\n",
    "    for _ in range(max_out_len):\n",
    "        # Decoder inference\n",
    "        pred, s, c = decoder_inf.predict([target_output, encoder_output, s, c])\n",
    "        \n",
    "        # update output seq\n",
    "        tok = np.argmax(pred.flatten())\n",
    "        if tok == eos:\n",
    "            break\n",
    "        if tok > 0:\n",
    "            word = idx2word_out[tok]\n",
    "            output_seq.append(word)\n",
    "\n",
    "        # Update decoder input\n",
    "        target_output[0, 0] = tok\n",
    "        \n",
    "    sentence = ' '.join(output_seq)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe some of the sample inference results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "English: Tom would never hurt you.\n",
      "Prediction: is ne aata. ziyada. ho\n",
      "acutual truth: tom kabhi tumhe dukh nahi day ga. <eos>\n",
      "--------------------------------------\n",
      "English: I'll be back soon.\n",
      "Prediction: ki nahi hi tha. ge? mein\n",
      "acutual truth: mein jald hi wapas aa jayo ga. <eos>\n",
      "--------------------------------------\n",
      "English: She will come if you ask her.\n",
      "Prediction: hai aap ke usay tum tak thi.\n",
      "acutual truth: agar tum usay pucho ge to woh aayi gi. <eos>\n",
      "--------------------------------------\n",
      "English: I am sorry. I am not from here.\n",
      "Prediction: is aur nahi chocolate qubool .\n",
      "acutual truth: mein moazrat chahta hon. <eos>\n",
      "--------------------------------------\n",
      "English: A heavy rain fell.\n",
      "Prediction: khanay satke satke tar woh woh woh ko mere\n",
      "acutual truth: kaafi taiz barish hui. <eos>\n"
     ]
    }
   ],
   "source": [
    "test_actual_sentence=[]\n",
    "test_predicted_sentence=[]\n",
    "for _ in range(5):\n",
    "    i = np.random.choice(len(engT))\n",
    "    eng_sen = eng_seq_paddedT[i:i+1]\n",
    "    man_pred = inference(eng_sen)\n",
    "\n",
    "    print('--------------------------------------')\n",
    "    print('English: {}'.format(engT[i]))\n",
    "    print('Prediction: {}'.format(man_pred))\n",
    "    print('acutual truth: {}'.format(manT[i])) \n",
    "    test_actual_sentence.append(engT[i])\n",
    "    test_predicted_sentence.append(man_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project implements an seq2seq model using LSTM and attention mechanism. It is observed that the model achieves an accuracy of 0.90 on validation data, although some of the translated sentences differ from the actual output to some extent but overall they look fine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "pred=[]\n",
    "for words in test_predicted_sentence:\n",
    "    pred.append(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=[]\n",
    "for words in test_actual_sentence:\n",
    "    actual.append(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09911919910483694\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "chencherry = SmoothingFunction()\n",
    "BLEUscore = nltk.translate.bleu_score.corpus_bleu(actual,pred,smoothing_function=chencherry.method4)\n",
    "print(BLEUscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 0.40 0.3/0.4/0.4/0.6 (BP = 1.000 ratio = 1.179 hyp_len = 33 ref_len = 28)\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "x=sacrebleu.raw_corpus_bleu(test_predicted_sentence,[test_actual_sentence])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
