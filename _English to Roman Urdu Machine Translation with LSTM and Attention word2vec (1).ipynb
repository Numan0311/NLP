{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will use straightforward application of multilayered long short-term memory (LSTM) architecture with attention-mechanism to map the input sequence to a vector of a fixed dimensionality, and then another LSTM to decode the target sequence from the vector. Our main focus will be on an English to Roman Urdu translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import basic libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set basic parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 10\n",
    "EPOCH = 100\n",
    "LATENT_DIM = 500\n",
    "LATENT_DIM_DECODER = LATENT_DIM\n",
    "SAMPLES = 1000\n",
    "MAX_WORD_NUM = SAMPLES\n",
    "MAX_SEQ_LEN = 100\n",
    "EMBEDDING = MAX_SEQ_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store data from textfile to usable arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Count: 100.\n",
      "Sample Count: 200.\n",
      "Sample Count: 300.\n",
      "Sample Count: 400.\n",
      "Sample Count: 500.\n",
      "Sample Count: 600.\n",
      "Sample Count: 700.\n",
      "Sample Count: 800.\n",
      "Sample Count: 900.\n"
     ]
    }
   ],
   "source": [
    "eng = []\n",
    "man = []\n",
    "man_inputs = []\n",
    "count = 0\n",
    "\n",
    "# preprocess the translation file\n",
    "for line in open('romanu.txt', 'r', encoding='utf-8'):\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    \n",
    "    count += 1\n",
    "    if (count > SAMPLES):\n",
    "        break\n",
    "    \n",
    "    # split original and translation into lists\n",
    "    e, m, _ = line.rstrip().split('\\t')\n",
    "    eng.append(e)\n",
    "    man.append(m + ' <eos>')\n",
    "    man_inputs.append('<sos> ' + m)\n",
    "    \n",
    "    if (count % 100 == 0):\n",
    "        print ('Sample Count: {}.'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Count: 100.\n",
      "Sample Count: 200.\n",
      "Sample Count: 300.\n"
     ]
    }
   ],
   "source": [
    "engT = []\n",
    "manT = []\n",
    "man_inputsT = []\n",
    "count = 0\n",
    "\n",
    "# preprocess the translation file\n",
    "for line in open('roman_train.txt', 'r', encoding='utf-8'):\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    \n",
    "    count += 1\n",
    "    if (count > SAMPLES):\n",
    "        break\n",
    "    \n",
    "    # split original and translation into lists\n",
    "    eT, mT, _ = line.rstrip().split('\\t')\n",
    "    engT.append(eT)\n",
    "    manT.append(mT + ' <eos>')\n",
    "    man_inputsT.append('<sos> ' + mT)\n",
    "    \n",
    "    if (count % 100 == 0):\n",
    "        print ('Sample Count: {}.'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the input and output sentences, and create maps that can be used by the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input tokens: 1185\n",
      "Maximum input sequence length: 17\n",
      "Number of output tokens: 1485\n",
      "Maximum output sequence length: 20\n"
     ]
    }
   ],
   "source": [
    "#train data tokenization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# tokenize input and generate idx map\n",
    "tok_in = Tokenizer(num_words=MAX_WORD_NUM)\n",
    "tok_in.fit_on_texts(eng)\n",
    "eng_seq = tok_in.texts_to_sequences(eng)\n",
    "word2idx_in = tok_in.word_index\n",
    "max_in_len = max(len(s) for s in eng_seq)\n",
    "\n",
    "print(\"Number of input tokens: {}\".format(len(word2idx_in)))\n",
    "print(\"Maximum input sequence length: {}\".format(max_in_len))\n",
    "\n",
    "# tokenize output and generate idx map\n",
    "tok_out = Tokenizer(num_words=MAX_WORD_NUM, filters='')\n",
    "tok_out.fit_on_texts(man + man_inputs)\n",
    "man_seq = tok_out.texts_to_sequences(man)\n",
    "man_seq_inputs = tok_out.texts_to_sequences(man_inputs)\n",
    "word2idx_out = tok_out.word_index\n",
    "max_out_len = max(len(s) for s in man_seq)\n",
    "out_word_num = len(word2idx_out) + 1\n",
    "\n",
    "print(\"Number of output tokens: {}\".format(len(word2idx_out)))\n",
    "print(\"Maximum output sequence length: {}\".format(max_out_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input tokens: 538\n",
      "Maximum input sequence length: 8\n",
      "Number of output tokens: 671\n",
      "Maximum output sequence length: 15\n"
     ]
    }
   ],
   "source": [
    "#test data tokenization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# tokenize input and generate idx map\n",
    "tok_inT = Tokenizer(num_words=MAX_WORD_NUM)\n",
    "tok_inT.fit_on_texts(engT)\n",
    "eng_seqT = tok_inT.texts_to_sequences(engT)\n",
    "word2idx_inT = tok_inT.word_index\n",
    "max_in_lenT = max(len(s) for s in eng_seqT)\n",
    "\n",
    "print(\"Number of input tokens: {}\".format(len(word2idx_inT)))\n",
    "print(\"Maximum input sequence length: {}\".format(max_in_lenT))\n",
    "\n",
    "# tokenize output and generate idx map\n",
    "tok_outT = Tokenizer(num_words=MAX_WORD_NUM, filters='')\n",
    "tok_outT.fit_on_texts(manT + man_inputsT)\n",
    "man_seqT = tok_out.texts_to_sequences(manT)\n",
    "man_seq_inputsT = tok_outT.texts_to_sequences(man_inputsT)\n",
    "word2idx_outT = tok_outT.word_index\n",
    "max_out_lenT = max(len(s) for s in man_seqT)\n",
    "out_word_numT = len(word2idx_outT) + 1\n",
    "\n",
    "print(\"Number of output tokens: {}\".format(len(word2idx_outT)))\n",
    "print(\"Maximum output sequence length: {}\".format(max_out_lenT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad the input and output sequences to be the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "eng_seq_padded = pad_sequences(eng_seq, maxlen=max_in_len)\n",
    "man_seq_padded = pad_sequences(man_seq, maxlen=max_out_len, padding='post')\n",
    "man_seq_inputs_padded = pad_sequences(man_seq_inputs, maxlen=max_out_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding for test dataset\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "eng_seq_paddedT = pad_sequences(eng_seqT, maxlen=max_in_len)\n",
    "man_seq_paddedT = pad_sequences(man_seqT, maxlen=max_out_len, padding='post')\n",
    "man_seq_inputs_paddedT = pad_sequences(man_seq_inputsT, maxlen=max_out_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in word2vec word vectors and use them to create word embeddings. [The dataset](https://github.com/alexandres/lexvec#pre-trained-vectors) from this link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wordVec\n",
      "Finished loading wordVec.\n"
     ]
    }
   ],
   "source": [
    "wordVec = {}\n",
    "\n",
    "print('Loading wordVec')\n",
    "import io\n",
    "\n",
    "fin = io.open('lexvec.enwiki+newscrawl.300d.W.pos.vectors', 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "n, d = map(lambda x: (str, int)[x.isdigit() or x.strip(\"-\").isdigit()](x), fin.readline().split())\n",
    "data = {}\n",
    "for line in fin:\n",
    "    tokens = line.rstrip().split(' ')\n",
    "    data[tokens[0]] = map(float, tokens[1:])\n",
    "print('Finished loading wordVec.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordNum = min(MAX_WORD_NUM, len(word2idx_in) + 1)\n",
    "word_embedding = np.zeros((wordNum, EMBEDDING))\n",
    "\n",
    "# create word embedding by fetching each word vector\n",
    "for tok, idx in word2idx_in.items():\n",
    "    if idx < MAX_WORD_NUM:\n",
    "        word_vector = wordVec.get(tok)\n",
    "        if word_vector is not None:\n",
    "            word_embedding[idx] = word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create translated target matrix by loading the padded output target sequence using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_target_one_hot = np.zeros((len(eng), max_out_len, out_word_num), dtype='float32')\n",
    "\n",
    "for idx, tokVec in enumerate(man_seq_padded):\n",
    "    for tok_idx, tok in enumerate(tokVec):\n",
    "        if (tok > 0):\n",
    "            man_target_one_hot[idx, tok_idx, tok] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the encoder and decoder before attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, LSTM, GRU, Dense, Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "# Embedding\n",
    "embedding = Embedding(wordNum, EMBEDDING, weights=[word_embedding], input_length=max_in_len)\n",
    "\n",
    "# Encoder\n",
    "input_layer_encoder = Input(shape=(max_in_len,))\n",
    "embed_encoder = embedding(input_layer_encoder)\n",
    "encoder = Bidirectional(LSTM(LATENT_DIM, return_sequences=True, dropout=0.2))\n",
    "encoder_out = encoder(embed_encoder)\n",
    "\n",
    "# Decoder input\n",
    "input_layer_decoder = Input(shape=(max_out_len,))\n",
    "embed_decoder = Embedding(out_word_num, EMBEDDING)\n",
    "decoder_input = embed_decoder(input_layer_decoder)\n",
    "\n",
    "# Decoder output, after attention\n",
    "decoder = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "dense_decode = Dense(out_word_num, activation='softmax')\n",
    "s0 = Input(shape=(LATENT_DIM_DECODER,))\n",
    "c0 = Input(shape=(LATENT_DIM_DECODER,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Attention. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of x is N x T x D.\n",
    "def softmax(x):\n",
    "    assert(K.ndim(x) > 2)\n",
    "    e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "    s = K.sum(e, axis=1, keepdims=True)\n",
    "    return e / s\n",
    "\n",
    "# Some of the common layers for attention\n",
    "repeat_attn = RepeatVector(max_in_len)\n",
    "concat_attn = Concatenate(axis=-1)\n",
    "dense1_attn = Dense(10, activation='tanh')  # over time dimension T\n",
    "dense2_attn = Dense(1, activation=softmax)\n",
    "dot_attn = Dot(axes=1)                      # over time dimension T\n",
    "\n",
    "def iterAttn(h, prevOut):\n",
    "    \"\"\"\n",
    "    h: encoder encoded hidden states at all time.\n",
    "    prevOut: output at the previous time (word).\n",
    "    An iteration of attention.\n",
    "    \"\"\"\n",
    "    prevOutRepeat = repeat_attn(prevOut) # Tx, LATENT_DIM_DECODE\n",
    "    total = concat_attn([h, prevOutRepeat]) # Tx, LATENT_DIM_DECODE + LATENT_DIM * 2\n",
    "    d = dense1_attn(total)\n",
    "    alphaLayer = dense2_attn(d)\n",
    "    context = dot_attn([alphaLayer, h])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute encoder-decoder and attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s0\n",
    "c = c0\n",
    "\n",
    "# Iterate attention Ty times\n",
    "all_out = []\n",
    "for t in range(max_out_len):\n",
    "    # Get context vector with encoder and attention\n",
    "    context = iterAttn(encoder_out, s) \n",
    "    \n",
    "    # For teacher forcing, get the previous word\n",
    "    select_layer = Lambda(lambda x: x[:, t:t+1])\n",
    "    prevWord = select_layer(decoder_input)\n",
    "    \n",
    "    # Concat context and previous word as decoder input\n",
    "    concat2 = Concatenate(axis=2)\n",
    "    decoder_in_concat = concat2([context, prevWord])\n",
    "    \n",
    "    # pass into decoder, inference output\n",
    "    pred, s, c = decoder(decoder_in_concat, initial_state=[s, c])\n",
    "    pred = dense_decode(pred)\n",
    "    all_out.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output needs to be stacked to be considered as the network's output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(outputs):\n",
    "    outputs = K.stack(outputs)\n",
    "    return K.permute_dimensions(outputs, pattern=(1, 0, 2))\n",
    "\n",
    "stack_layer = Lambda(stack)\n",
    "all_out = stack_layer(all_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "attnModel = Model(inputs=[input_layer_encoder, input_layer_decoder, s0, c0,],\n",
    "                 outputs=all_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define customized loss and accuracy metrics for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myLoss(y_train, pred):\n",
    "    mask = K.cast(y_train > 0, dtype='float32')\n",
    "    val = mask * y_train * K.log(pred)\n",
    "    return -K.sum(val) / K.sum(mask)\n",
    "\n",
    "def acc(y_train, pred):\n",
    "    targ = K.argmax(y_train, axis=-1)\n",
    "    pred = K.argmax(pred, axis=-1)\n",
    "    correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
    "\n",
    "    mask = K.cast(K.greater(targ, 0), dtype='float32') # filter out padding value 0.\n",
    "    correctCount = K.sum(mask * correct)\n",
    "    totalCount = K.sum(mask)\n",
    "    return correctCount / totalCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model using Adam optimizer and defined loss and metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 1/100\n",
      "71/71 [==============================] - 136s 727ms/step - loss: 6.2666 - acc: 0.1279 - val_loss: 5.7645 - val_acc: 0.1100\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 31s 435ms/step - loss: 5.0491 - acc: 0.1775 - val_loss: 6.0137 - val_acc: 0.1181\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 31s 434ms/step - loss: 4.8609 - acc: 0.1846 - val_loss: 5.9717 - val_acc: 0.1169\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 31s 437ms/step - loss: 4.7220 - acc: 0.1885 - val_loss: 6.0979 - val_acc: 0.1266\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 31s 443ms/step - loss: 4.5405 - acc: 0.1924 - val_loss: 6.2605 - val_acc: 0.1274\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 31s 439ms/step - loss: 4.4607 - acc: 0.1952 - val_loss: 6.4584 - val_acc: 0.1236\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 32s 446ms/step - loss: 4.3143 - acc: 0.2054 - val_loss: 6.4478 - val_acc: 0.1291\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 31s 441ms/step - loss: 4.2277 - acc: 0.2048 - val_loss: 6.6661 - val_acc: 0.1226\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 36s 507ms/step - loss: 4.1911 - acc: 0.2049 - val_loss: 6.9588 - val_acc: 0.1274\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 31s 440ms/step - loss: 4.0966 - acc: 0.2090 - val_loss: 6.9091 - val_acc: 0.1224\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 31s 430ms/step - loss: 4.0170 - acc: 0.2084 - val_loss: 6.9367 - val_acc: 0.1279\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 30s 428ms/step - loss: 3.9668 - acc: 0.2134 - val_loss: 7.1832 - val_acc: 0.1256\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 31s 433ms/step - loss: 3.8930 - acc: 0.2177 - val_loss: 7.1299 - val_acc: 0.1290\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 31s 430ms/step - loss: 3.8457 - acc: 0.2182 - val_loss: 7.1723 - val_acc: 0.1243\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 31s 434ms/step - loss: 3.8306 - acc: 0.2084 - val_loss: 7.3082 - val_acc: 0.1285\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 31s 441ms/step - loss: 3.9030 - acc: 0.2048 - val_loss: 7.1207 - val_acc: 0.1209\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 31s 438ms/step - loss: 3.7839 - acc: 0.2196 - val_loss: 7.2051 - val_acc: 0.1212\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 31s 439ms/step - loss: 3.7429 - acc: 0.2103 - val_loss: 7.3680 - val_acc: 0.1302\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 31s 438ms/step - loss: 3.7074 - acc: 0.2169 - val_loss: 7.4615 - val_acc: 0.1227\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 31s 438ms/step - loss: 3.6523 - acc: 0.2206 - val_loss: 7.4619 - val_acc: 0.1269\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 32s 444ms/step - loss: 3.5603 - acc: 0.2384 - val_loss: 7.5576 - val_acc: 0.1211\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 35s 492ms/step - loss: 3.5196 - acc: 0.2230 - val_loss: 7.5211 - val_acc: 0.1194\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 31s 433ms/step - loss: 3.5114 - acc: 0.2368 - val_loss: 7.3663 - val_acc: 0.1153\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 31s 435ms/step - loss: 3.7322 - acc: 0.2115 - val_loss: 7.4891 - val_acc: 0.1204\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 31s 431ms/step - loss: 3.4724 - acc: 0.2280 - val_loss: 7.7187 - val_acc: 0.1215\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 31s 432ms/step - loss: 3.3567 - acc: 0.2415 - val_loss: 7.6653 - val_acc: 0.1184\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 31s 432ms/step - loss: 3.3190 - acc: 0.2453 - val_loss: 7.6900 - val_acc: 0.1190\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 31s 431ms/step - loss: 3.3355 - acc: 0.2367 - val_loss: 7.8887 - val_acc: 0.1194\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 31s 434ms/step - loss: 3.2082 - acc: 0.2463 - val_loss: 7.8998 - val_acc: 0.1159\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 31s 434ms/step - loss: 3.2008 - acc: 0.2538 - val_loss: 8.0611 - val_acc: 0.1145\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 31s 444ms/step - loss: 3.0938 - acc: 0.2656 - val_loss: 8.1674 - val_acc: 0.1159\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 31s 439ms/step - loss: 3.1131 - acc: 0.2579 - val_loss: 8.1237 - val_acc: 0.1133\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 31s 443ms/step - loss: 3.1058 - acc: 0.2564 - val_loss: 8.1711 - val_acc: 0.1136\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 31s 437ms/step - loss: 3.0495 - acc: 0.2487 - val_loss: 8.4001 - val_acc: 0.1168\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 31s 440ms/step - loss: 2.9348 - acc: 0.2809 - val_loss: 8.2398 - val_acc: 0.1086\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 31s 438ms/step - loss: 2.9396 - acc: 0.2747 - val_loss: 8.3762 - val_acc: 0.1159\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 31s 438ms/step - loss: 2.7898 - acc: 0.3033 - val_loss: 8.4241 - val_acc: 0.1110\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 31s 441ms/step - loss: 2.8083 - acc: 0.2894 - val_loss: 8.2075 - val_acc: 0.1028\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 31s 440ms/step - loss: 2.7718 - acc: 0.3035 - val_loss: 8.5217 - val_acc: 0.1139\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 31s 442ms/step - loss: 2.6745 - acc: 0.3136 - val_loss: 8.5833 - val_acc: 0.1123\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 31s 444ms/step - loss: 2.6962 - acc: 0.3027 - val_loss: 8.5816 - val_acc: 0.1107\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 31s 441ms/step - loss: 2.7134 - acc: 0.3155 - val_loss: 8.6210 - val_acc: 0.1075\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 31s 442ms/step - loss: 2.5709 - acc: 0.3328 - val_loss: 8.6601 - val_acc: 0.1080\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 32s 445ms/step - loss: 2.5020 - acc: 0.3412 - val_loss: 8.6494 - val_acc: 0.1065\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 31s 441ms/step - loss: 2.4256 - acc: 0.3402 - val_loss: 8.6544 - val_acc: 0.1121\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 32s 448ms/step - loss: 2.3390 - acc: 0.3712 - val_loss: 8.7444 - val_acc: 0.1051\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 32s 446ms/step - loss: 2.3059 - acc: 0.3741 - val_loss: 8.9537 - val_acc: 0.1049\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 33s 460ms/step - loss: 2.2155 - acc: 0.3935 - val_loss: 8.9940 - val_acc: 0.1048\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 31s 441ms/step - loss: 2.1720 - acc: 0.3994 - val_loss: 9.0278 - val_acc: 0.1015\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 32s 448ms/step - loss: 2.0562 - acc: 0.4432 - val_loss: 8.9996 - val_acc: 0.1022\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 31s 442ms/step - loss: 2.0055 - acc: 0.4436 - val_loss: 9.3455 - val_acc: 0.1063\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 32s 447ms/step - loss: 1.9907 - acc: 0.4431 - val_loss: 9.2510 - val_acc: 0.1017\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 31s 441ms/step - loss: 1.8745 - acc: 0.4777 - val_loss: 9.1306 - val_acc: 0.1041\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 31s 444ms/step - loss: 1.8391 - acc: 0.4894 - val_loss: 9.3203 - val_acc: 0.1023\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 32s 445ms/step - loss: 1.7900 - acc: 0.4874 - val_loss: 9.3184 - val_acc: 0.1036\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 32s 453ms/step - loss: 1.6970 - acc: 0.5448 - val_loss: 9.5013 - val_acc: 0.1023\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 32s 451ms/step - loss: 1.6293 - acc: 0.5498 - val_loss: 9.3894 - val_acc: 0.0987\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 31s 443ms/step - loss: 1.6741 - acc: 0.5331 - val_loss: 9.4774 - val_acc: 0.1008\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 33s 470ms/step - loss: 1.5249 - acc: 0.5816 - val_loss: 9.5302 - val_acc: 0.0972\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 33s 461ms/step - loss: 1.4027 - acc: 0.6084 - val_loss: 9.5238 - val_acc: 0.0940\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 36s 514ms/step - loss: 1.4082 - acc: 0.5931 - val_loss: 9.7643 - val_acc: 0.1031\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 37s 517ms/step - loss: 1.2353 - acc: 0.6546 - val_loss: 9.7734 - val_acc: 0.0961\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 34s 486ms/step - loss: 1.3059 - acc: 0.6344 - val_loss: 9.9021 - val_acc: 0.0996\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 34s 486ms/step - loss: 1.2290 - acc: 0.6540 - val_loss: 9.8366 - val_acc: 0.1017\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 33s 470ms/step - loss: 1.0926 - acc: 0.6950 - val_loss: 9.9885 - val_acc: 0.0994\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 35s 498ms/step - loss: 1.1096 - acc: 0.7018 - val_loss: 9.9978 - val_acc: 0.1003\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 36s 503ms/step - loss: 1.1817 - acc: 0.6659 - val_loss: 10.0671 - val_acc: 0.0969\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 33s 469ms/step - loss: 1.0787 - acc: 0.7008 - val_loss: 10.1442 - val_acc: 0.1012\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 33s 470ms/step - loss: 0.9995 - acc: 0.7173 - val_loss: 10.1121 - val_acc: 0.0973\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 33s 469ms/step - loss: 0.9546 - acc: 0.7250 - val_loss: 10.2233 - val_acc: 0.0970\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 34s 480ms/step - loss: 0.8949 - acc: 0.7500 - val_loss: 10.3332 - val_acc: 0.0985\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 33s 470ms/step - loss: 0.8082 - acc: 0.7715 - val_loss: 10.2092 - val_acc: 0.1036\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 33s 470ms/step - loss: 0.8111 - acc: 0.7642 - val_loss: 10.3311 - val_acc: 0.1028\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 33s 468ms/step - loss: 0.7066 - acc: 0.7991 - val_loss: 10.5324 - val_acc: 0.1033\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 33s 470ms/step - loss: 0.6956 - acc: 0.8013 - val_loss: 10.6164 - val_acc: 0.1020\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 34s 476ms/step - loss: 0.6716 - acc: 0.8092 - val_loss: 10.7663 - val_acc: 0.0983\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 33s 468ms/step - loss: 0.6095 - acc: 0.8322 - val_loss: 10.5354 - val_acc: 0.0957\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 33s 465ms/step - loss: 0.6052 - acc: 0.8196 - val_loss: 10.7938 - val_acc: 0.0994\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 33s 465ms/step - loss: 0.5295 - acc: 0.8464 - val_loss: 10.7920 - val_acc: 0.0973\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 33s 466ms/step - loss: 0.5611 - acc: 0.8366 - val_loss: 10.9447 - val_acc: 0.1005\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 34s 474ms/step - loss: 0.6727 - acc: 0.7955 - val_loss: 10.7830 - val_acc: 0.1006\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 34s 478ms/step - loss: 0.5036 - acc: 0.8469 - val_loss: 10.9010 - val_acc: 0.1031\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 33s 468ms/step - loss: 0.4927 - acc: 0.8481 - val_loss: 11.0613 - val_acc: 0.1032\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 34s 478ms/step - loss: 0.4651 - acc: 0.8576 - val_loss: 10.9253 - val_acc: 0.1043\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 33s 468ms/step - loss: 0.4601 - acc: 0.8541 - val_loss: 11.1168 - val_acc: 0.1007\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 34s 477ms/step - loss: 0.4547 - acc: 0.8607 - val_loss: 10.8060 - val_acc: 0.0954\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 33s 464ms/step - loss: 0.4936 - acc: 0.8464 - val_loss: 11.0005 - val_acc: 0.1027\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 31s 435ms/step - loss: 0.4096 - acc: 0.8743 - val_loss: 11.0072 - val_acc: 0.1022\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 31s 434ms/step - loss: 0.4166 - acc: 0.8645 - val_loss: 11.2749 - val_acc: 0.1015\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 31s 435ms/step - loss: 0.3616 - acc: 0.8820 - val_loss: 11.1536 - val_acc: 0.1037\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 31s 433ms/step - loss: 0.3607 - acc: 0.8670 - val_loss: 11.3169 - val_acc: 0.1007\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 31s 434ms/step - loss: 0.3740 - acc: 0.8694 - val_loss: 11.3560 - val_acc: 0.1038\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 31s 432ms/step - loss: 0.4028 - acc: 0.8585 - val_loss: 11.3072 - val_acc: 0.1074\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 31s 438ms/step - loss: 0.3508 - acc: 0.8711 - val_loss: 11.3749 - val_acc: 0.1000\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 32s 448ms/step - loss: 0.3066 - acc: 0.8875 - val_loss: 11.5007 - val_acc: 0.1034\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 33s 462ms/step - loss: 0.3003 - acc: 0.8906 - val_loss: 11.5654 - val_acc: 0.1048\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 32s 452ms/step - loss: 0.3151 - acc: 0.8760 - val_loss: 11.5355 - val_acc: 0.1063\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 31s 442ms/step - loss: 0.2589 - acc: 0.8972 - val_loss: 11.6070 - val_acc: 0.1063\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 32s 448ms/step - loss: 0.3027 - acc: 0.8798 - val_loss: 11.6991 - val_acc: 0.1042\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 32s 445ms/step - loss: 0.3175 - acc: 0.8708 - val_loss: 11.5637 - val_acc: 0.0986\n"
     ]
    }
   ],
   "source": [
    "attnModel.compile(optimizer='Adam', loss=myLoss, metrics=[acc])\n",
    "\n",
    "# Define empty s0 and c0\n",
    "init_s = np.zeros((len(eng_seq_padded), LATENT_DIM_DECODER))\n",
    "init_c = np.zeros((len(eng_seq_padded), LATENT_DIM_DECODER))\n",
    "\n",
    "print(BATCHSIZE)\n",
    "\n",
    "# Train\n",
    "history = attnModel.fit(\n",
    "    x=[eng_seq_padded, man_seq_padded, init_s, init_c],\n",
    "    y=man_target_one_hot,\n",
    "    batch_size=BATCHSIZE,\n",
    "    epochs=EPOCH,\n",
    "    validation_split=0.22\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['acc'], label='acc')\n",
    "plt.plot(history.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "attnModel.save('attention_model_35_man.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in the inference model teacher forcing is not available, thus the model needs to be modified to use the previous inference result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inf = Model(input_layer_encoder, encoder_out)\n",
    "encoder_out_inf = Input(shape=(max_in_len, LATENT_DIM * 2,))\n",
    "\n",
    "# Decoder\n",
    "decoder_in_inf = Input(shape=(1,))\n",
    "decoder_in_embed_inf = embed_decoder(decoder_in_inf)\n",
    "\n",
    "# Context, concat without teacher forcing.\n",
    "context_inf = iterAttn(encoder_out_inf, s0)\n",
    "decoder_in_concat_inf = concat2([context_inf, decoder_in_embed_inf])\n",
    "\n",
    "# Decoder inference\n",
    "pred, s, c = decoder(decoder_in_concat_inf, initial_state=[s0, c0])\n",
    "pred_out = dense_decode(pred)\n",
    "\n",
    "# Define model\n",
    "decoder_inf = Model(\n",
    "    inputs=[decoder_in_inf, encoder_out_inf, s0, c0],\n",
    "    outputs=[pred_out, s, c]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse the word-to-index maps to convert translated indices to words. Then use the inference encoder and decoder models to create predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_in = {b:a for a, b in word2idx_inT.items()}\n",
    "idx2word_out = {b:a for a, b in word2idx_outT.items()}\n",
    "\n",
    "def inference(eng_seq):\n",
    "    # Encode\n",
    "    encoder_output = encoder_inf.predict(eng_seq)\n",
    "    \n",
    "    # Create output seq matrix\n",
    "    target_output = np.zeros((1, 1))\n",
    "    target_output[0, 0] = word2idx_outT['<sos>']\n",
    "    \n",
    "    # init\n",
    "    eos = word2idx_outT['<eos>']\n",
    "    s0 = np.zeros((1, LATENT_DIM_DECODER))\n",
    "    c0 = np.zeros((1, LATENT_DIM_DECODER))\n",
    "    \n",
    "    output_seq = []\n",
    "    s = s0\n",
    "    c = c0\n",
    "    for _ in range(max_out_len):\n",
    "        # Decoder inference\n",
    "        pred, s, c = decoder_inf.predict([target_output, encoder_output, s, c])\n",
    "        \n",
    "        # update output seq\n",
    "        tok = np.argmax(pred.flatten())\n",
    "        if tok == eos:\n",
    "            break\n",
    "        if tok > 0:\n",
    "            word = idx2word_out[tok]\n",
    "            output_seq.append(word)\n",
    "\n",
    "        # Update decoder input\n",
    "        target_output[0, 0] = tok\n",
    "        \n",
    "    sentence = ' '.join(output_seq)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe some of the sample inference results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "English: You can go wherever you want.\n",
      "Prediction: mujhe logon ko hon. mein\n",
      "acutual truth: tum jahan jana chaho ja satke ho. <eos>\n",
      "--------------------------------------\n",
      "English: Please speak more loudly.\n",
      "Prediction: hai yeh satke theek farigh\n",
      "acutual truth: braay meharbani thora ouncha bolay. <eos>\n",
      "--------------------------------------\n",
      "English: I don't know her.\n",
      "Prediction: raha ne apni taqreeban bharr\n",
      "acutual truth: mein uss ( larki ) ko nahi jaanta. <eos>\n",
      "--------------------------------------\n",
      "English: I am older than your brother.\n",
      "Prediction: is nahi shukriya nahi woh ki.\n",
      "acutual truth: mein tumahray bhai se bara hon. <eos>\n",
      "--------------------------------------\n",
      "English: This is too big.\n",
      "Prediction: kab aaya. ka ka tum hai. tum ko\n",
      "acutual truth: yeh bohat bara hai. <eos>\n"
     ]
    }
   ],
   "source": [
    "test_actual_sentence=[]\n",
    "test_predicted_sentence=[]\n",
    "for _ in range(5):\n",
    "    i = np.random.choice(len(engT))\n",
    "    eng_sen = eng_seq_paddedT[i:i+1]\n",
    "    man_pred = inference(eng_sen)\n",
    "\n",
    "    print('--------------------------------------')\n",
    "    print('English: {}'.format(engT[i]))\n",
    "    print('Prediction: {}'.format(man_pred))\n",
    "    print('acutual truth: {}'.format(manT[i])) \n",
    "    test_actual_sentence.append(engT[i])\n",
    "    test_predicted_sentence.append(man_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project implements an seq2seq model using LSTM and attention mechanism. It is observed that the model achieves an accuracy of 0.90 on validation data, although some of the translated sentences differ from the actual output to some extent but overall they look fine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "pred=[]\n",
    "for words in test_predicted_sentence:\n",
    "    pred.append(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=[]\n",
    "for words in test_actual_sentence:\n",
    "    actual.append(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "chencherry = SmoothingFunction()\n",
    "BLEUscore = nltk.translate.bleu_score.corpus_bleu(actual,pred,smoothing_function=chencherry.method4)\n",
    "print(BLEUscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 0.48 0.3/0.4/0.5/0.7 (BP = 1.000 ratio = 1.208 hyp_len = 29 ref_len = 24)\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "x=sacrebleu.raw_corpus_bleu(test_predicted_sentence,[test_actual_sentence])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
